# 数据结构中的垃圾收集

> 原文：<https://www.javatpoint.com/garbage-collection-in-data-structure>

垃圾收集(GC)是一种用于内存管理和堆分配的动态技术，它在重新分配存储以供重用之前检查并识别死内存块。垃圾收集的主要目标是减少内存泄漏。垃圾收集使程序员不必手动释放对象并将对象返回内存系统。垃圾收集会占用程序相当多的总处理时间，因此会对性能产生重大影响。堆栈分配、区域推断、内存所有权以及各种技术的组合都是相关技术的示例。

垃圾收集的基本原则是在程序中查找无法访问的数据对象

并回收这些对象使用的资源。垃圾收集通常不处理内存以外的资源，如网络套接字、数据库句柄、用户交互窗口、文件和设备描述符。管理这些资源的方法，尤其是析构函数，可能足以管理内存，而不需要 GC。在某些垃圾收集系统中，其他资源可能与内存扇区相关联，当收集这些资源时，会导致回收这些资源的任务。

许多编程语言，如 RPL、Java、C#、Go 和大多数脚本语言，需要垃圾收集，要么作为语言规范的一部分，要么为了实际实现而有效(例如，像 lambda 演算这样的正式语言)；这些被称为垃圾收集语言。其他语言，如 C 和 C++，设计用于手动内存管理，但包括垃圾收集实现。有些语言，如 Ada、Modula-3 和 C++/CLI，通过对收集的和手动管理的对象使用单独的堆，允许在同一应用程序中进行垃圾收集和手动内存管理；其他的，如 D，是垃圾收集的，但允许用户手动删除对象，并在需要速度时完全禁用垃圾收集。

垃圾收集的自动堆分配的动态方法解决了常见且代价高昂的错误，如果不被发现，可能会导致现实世界的程序员问题。

分配错误代价高昂，因为它们难以检测和纠正。因此，许多程序员将垃圾收集视为一项必不可少的语言功能，通过减少手动堆分配管理来简化程序员的工作。

现在让我们来看看一些最著名和最常用的垃圾收集技术。

*   标记和扫描
*   参考计数

### 标记和扫描

标记扫描算法就像它的名字一样简单。它由两个阶段组成:标记阶段和扫描阶段。收集器遍历所有根(全局变量、局部变量、堆栈帧、虚拟和硬件寄存器等)，并通过在标记阶段在对象周围的任何地方设置一个位来标记它遇到的每个项目。它还在扫描阶段遍历堆，从所有未标记的项目中回收内存。

下面用 Python 伪代码概述了基本算法。在本例中，假设收集器是单线程的，尽管可能有几个变异器。当收集器运行时，所有的 mutator 线程都会暂停。这种停止世界的技术可能看起来效率不高，但是它极大地简化了收集器的实现，因为变异器不能影响它下面的状态。

**代码**

```

def gc():
    stop_all_mutators()
    mark_roots()
    sweep()
    resume_all_mutators()

def mark_roots():
    candidates = Stack()
    for field in Roots:
        if field != nil && not is_marked(field):
            set_marked(field)
            candidates.push(field)
            mark(candidates)

def mark(candidates):
    while not candidates.empty():
        ref = candidates.pop()
        for field in pointers(ref):
            if field != nil && not is_marked(field):
                set_marked(field)
                candidates.push(field)

def sweep():
    scan = start_of_heap()
    end = end_of_heap()
    while scan < end:
        if is_marked(scan):
            unset_marked(scan)
        else:
            free(scan)
        scan = next_object(scan)

def next_object(address):
    # Parse the heap and return the next object.
    ...

```

从伪代码中可以明显看出，标记扫描不能立即识别垃圾。相反，它会先识别出所有不是垃圾的物品，比如生物，然后再断定其他东西都是垃圾。标记的过程是一个循环的过程。在检测到活动引用之后，我们递归到它的子字段中，以此类推。由于堆栈溢出的时间成本和风险，递归过程调用不是标记的合适方式。这就是为什么我们使用一个明确定义的堆栈。通过这种技术，标记阶段的空间和时间开销都变得很明显。必须通过对象图跟踪的最长路径的大小决定了候选堆栈的最大深度。

理论上，最坏的情况等于堆上的节点数。然而，大多数现实世界的应用程序产生相当浅的堆栈。尽管如此，一个安全的垃圾收集系统必须处理不寻常的情况。在我们的实现中，在向候选对象添加新对象之后，我们使用**标记()**来控制堆栈大小。标记的问题在于，需要 GC 正是因为内存很少，而辅助堆栈需要更多的空间。大型应用程序可能会导致垃圾收集器耗尽内存。

检测溢出有多种方法。使用显式堆栈的一个优点是可以立即识别溢出并启动恢复过程。每次推送都使用内联签入是一种简单的方法()。使用保护页面并在捕获保护违规异常后触发恢复可能是一种更有效的解决方案。这两种技术的权衡必须在底层操作系统和硬件的背景下考虑。在第一种技术中，is-full 测试可能会花费一些指令(测试之后是一个分支)，但是它会在我们每次检查一个对象时执行。第二种技术需要捕获访问冲突异常，这种异常通常代价很高，但并不常见。

**Sweep()** 是一个简单的函数，实现简单明了。它线性遍历堆，释放任何没有标记的对象。因此，我们的堆布局确实面临可解析性的限制。下一个对象(地址)实现必须能够返回堆的下一个对象。在大多数情况下，堆只需要在一个方面是可解析的。在大多数支持垃圾收集的语言运行时中，对象的数据通常用对象头来标记。标题提供了项目的详细信息，如类型、大小、hashcode、标记位、同步块等。

对象的标题通常放在对象数据的前面。因此，对象的引用指向紧接在对象头之后的已分配堆单元的中间，而不是第一个字节。这使得从上到下解析堆变得更加容易。在大多数情况下，free(address)将用堆解析算法识别的预定填充模式来填充被释放的单元。

### 标记和扫描算法的优势

*   硬件缓存的使用效率通常是大多数应用程序性能的决定因素。现在，可以在 2 到 10 个 CPU 周期内访问 L1-L3 缓存，而内存最多需要 100 个周期。缓存有助于具有良好时间和空间局部性的应用程序更好地运行。当一个程序访问一个最近被访问过的内存位置时，它被称为临时本地。如果一个程序以类似扫描的方式访问附近的存储区域，它就具有很高的空间局部性。不幸的是，就时间和地理位置而言，标记扫描算法中的标记阶段非常失败。对象的头通常在 mark()中只读写一次(假设大多数对象都很流行，并且只被一个指针引用)。我们读取标记位，如果对象还没有被标记，就不会再被访问。硬件预取(无论是推测性的还是通过显式预取指令)对于这种不稳定的指针追踪并不理想。提高缓存速度的一个典型策略是将标记位放在单独的位图中，而不是将标记位作为对象头的一部分。位图的格式、位置和大小由各种参数决定，包括堆大小、对象对齐要求、硬件缓存大小等。标记扫描算法在性能方面受益于这些标记位图。例如，标记不需要修改对象；许多对象可以用一条指令来标记(对位图字进行位打击)。因为它改变的字更少，所以它生成的脏缓存线更少，导致缓存刷新更少。扫描不需要读取任何活动对象，并且可能完全依赖于位图进行堆扫描。
*   标记阶段有一个 O(L)复杂度，其中 L 是从所有根可访问的活对象的大小。扫描阶段的时间复杂度是 O(H)，其中 H 是堆单元的数量。假设 H > L，很容易认为 O(H)支配 O(L)，但实际上，由于高空间局部性，扫描阶段具有出色的缓存性能，但由于所有对缓存不友好的指针追逐，整个收集速度由 O(L)支配。
*   因为标记是一个昂贵的过程，它只在有限的基础上进行(只有在需要时)。与引用计数技术相比，标记-清除方法使用更少的空间，可以干净地处理循环结构，而没有任何指针操作的复杂性。像其他跟踪算法一样，它需要一定的堆空间才能运行。此外，由于标记-清除不会压缩堆，系统可能会经历更多的内部碎片，导致堆利用率降低(尤其是对于较大的分配)。
*   利用 mutator 的读写操作，标记-清除基本上不会增加协调开销。对象分配函数是与变异器交互的唯一方式，即使这样，开销也很小。
*   一般来说，标记扫描系统需要复杂的分配器来理解和支持堆解析和位图操作。堆管理器可能需要设计非平凡的实现解决方案来处理内部碎片。另一方面，标记扫描因为不移动对象，所以非常适合在语言运行时与垃圾收集器不协调的非协作环境中使用(如果垃圾收集器是在语言设计中事后才引入的，这种情况就会发生)。不移动的另一个好处是对象地址不会改变。因此，扫描阶段后不需要打补丁。

### 参考计数

引用计数的方法真的很简单。它基于计算每个分配的对象有多少指针引用。这是一个简单的、固有的增量解决方案，因为程序的内存管理开销是分布式的。除了内存管理，引用计数在操作系统中被广泛用作管理文件、套接字等系统资源的资源管理工具。

引用计数技术中的每个分配对象都有一个引用计数字段。内存管理器负责确保每个对象的引用计数始终等于该对象的直接指针引用数。下面是算法的简化版本。

**代码**

```

# new() allocates a new object. For brevity, we've ignored the object types and
# assumed that all objects are of the same type and size.
def new():
	obj = allocate_memory()
	obj.set_reference_count(1)
	return obj

# delete() is invoked when an object is no longer required by the client program
def delete(obj):
	obj.decrement_reference_count()
	if obj.get_reference_count() == 0:
		for child in children(obj):
			delete(child)
		release_memory(obj)

# update() is the only blessed way to perform pointer assignments in the system.
def update(source, target):
	# We increment before deleting, this correctly deals with source == target case.
	target.increment_reference_count()
	delete(source)
	source = target

```

无法恢复循环存储是引用计数最显著的缺点。使用简单的引用计数技术无法成功恢复循环数据结构，如双链表和非基本图，并且会泄漏内存。

### 参考计数的优势

*   与跟踪收集器相比，内存管理成本分散在整个应用程序中，从而使系统更加流畅和响应迅速。值得注意的是，处理成本与最终指针引用的子图的大小成正比，而且并不总是微不足道的。
*   一个引用计数系统的空间局部性通常不比实际的客户端程序差，通常比跟踪 GCs 要好，GCs 必须跟踪所有的活动对象。
*   与跟踪收集器不同，跟踪收集器在收集器执行之前不分配不可访问的内存(通常在堆耗尽时)，引用计数技术允许立即重用浪费的内存。由于即时重用，缓存具有更大的时间局部性，导致页面错误更少。它还使资源清理变得更容易，因为终结器可以立即调用，从而加快系统资源的释放。空间的即时重用也允许诸如就地数据结构修改之类的改进。
*   就技术细节而言，基于引用计数的收集是最简单的垃圾收集方法。如果语言运行时不支持指针操作和/或程序员不能确定/操作对象根，那么实现非常简单。
*   程序员可以使用引用计数技术完全控制对象的分配和解除分配。程序员有可能在被认为安全的地方优化掉引用计数成本。这代表了准确性方面的困难，因此需要更高水平的代码规范。即使没有智能优化，客户端应用程序的接口和引用计数方法也是紧密耦合的。客户端必须适当调用增加和减少引用计数的操作。
*   每个项目都带有引用计数字段上方的空间。理论上，这可能相当于非常小的项目的 50%的开销。必须根据存储单元可以立即重用以及引用计数在收集期间不利用堆空间的事实来考虑这一开销。引用计数系统可以通过使用单个字节来节省空间，而不是使用一个完整的字来进行引用计数。这种系统使用回退跟踪机制(如标记扫描)来收集引用计数和引用计数(以及循环引用)达到最大值的对象。
*   与跟踪技术不同，在跟踪技术中指针变化是自由的，引用计数有很大的成本，因为每次指针更新都需要更新两次引用计数来保持程序有效。
*   如前所述，引用计数的主要缺陷是无法恢复循环存储。使用简单的引用计数技术无法成功恢复循环数据结构，如双链表和非基本图，并且会泄漏内存。

### 结论

因此，在本文中，我们已经了解了数据结构中的垃圾收集以及垃圾收集对于提高不同数据结构的效率的重要性。我们还了解了两种主要的垃圾收集算法:标记和扫描以及引用计数，以及这两种算法的工作原理，以及上面提到的这些垃圾收集算法的突出优点。

* * *